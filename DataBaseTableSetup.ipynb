{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os \n",
    "from tidypython import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv (r'/Users/aceinna_rishit/Documents/AWS/naukri_jobs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating job_title table\n",
    "job_posting = pd.DataFrame()\n",
    "job_posting['job_title'] = df['Title'].str.strip()\n",
    "job_posting['company_name'] = df['Company_Name'].str.strip()\n",
    "job_posting['category'] = df['Category'].str.strip()\n",
    "job_posting['role_category'] = df['Role_Category'].str.strip()\n",
    "job_posting['job_role'] = df['Job_Role'].str.strip()\n",
    "job_posting['functional_area'] = df['Functional_Area'].str.strip()\n",
    "job_posting['employment_type'] = df['Employment_Type'].str.strip()\n",
    "job_posting['salary'] = df['Salary'].str.strip()\n",
    "job_posting['experience'] = df['Experience'].str.strip()\n",
    "job_posting['location'] = df['Location'].str.strip()\n",
    "job_posting['skills'] = df['Extracted_Skills'].str.strip()\n",
    "job_posting['job_url'] = df['Url'].str.strip()\n",
    "job_posting.insert(0,'job_id', range(0,len(job_posting)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Removes the entry if any of the groupby field is empty\n",
    "grouped_title = job_posting.groupby(['job_title','company_name', 'category', 'role_category','functional_area','employment_type','salary','experience','location','skills','job_url'])\n",
    "job_title = pd.DataFrame()\n",
    "job_title = grouped_title.agg({'job_id':'size'}).rename(columns={'job_id':'count_jobs'}).reset_index()\n",
    "job_title.insert(0,'title_id', range(0,len(job_title['job_title'])))\n",
    "# job_title.set_index('title_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a DF of unique categories from job_posting['company_name']\n",
    "company_unique = pd.DataFrame(data=job_posting['company_name'].unique(), columns=[\"company_name\"])\n",
    "# Add inddex Column\n",
    "company_unique.insert(0,'company_id', range(0,len(job_title['company_name'])-1))\n",
    "company_dict = dict(zip(company_unique['company_name'], company_unique['company_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a DF of unique categories from job_posting['category']\n",
    "category_unique = pd.DataFrame(data=job_posting['category'].unique(), columns=[\"category\"])\n",
    "# Add inddex Column\n",
    "category_unique.reset_index(level=0, inplace=True)\n",
    "# Here .insert() to insert index column gives indexing error so manually changing the name of column after creation\n",
    "category_unique.rename(columns={'index': 'caterogy_id'}, inplace=True)\n",
    "category_dict = dict(zip(category_unique['category'], category_unique['caterogy_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a DF of unique categories from job_posting['role_category']\n",
    "role_category_unique = pd.DataFrame(data=job_posting['role_category'].dropna().unique(), columns=[\"role_category\"])\n",
    "# Add inddex Column\n",
    "role_category_unique.reset_index(level=0, inplace=True)\n",
    "# Here .insert() to insert index column gives indexing error so manually changing the name of column after creation\n",
    "role_category_unique.rename(columns={'index': 'role_category_id'}, inplace=True)\n",
    "role_category_dict = dict(zip(role_category_unique['role_category'], role_category_unique['role_category_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a DF of unique categories from job_posting['category']\n",
    "job_role_unique = pd.DataFrame(data=job_posting['job_role'].unique(), columns=[\"job_role\"])\n",
    "# Add inddex Column\n",
    "job_role_unique.reset_index(level=0, inplace=True)\n",
    "# Here .insert() to inser index column give indexing error so manually changing the name of column after creation\n",
    "job_role_unique.rename(columns={'index': 'job_role_id'}, inplace=True)\n",
    "job_role_dict = dict(zip(job_role_unique['job_role'], job_role_unique['job_role_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a DF of unique categories from job_posting['category']\n",
    "employment_data_unique = pd.DataFrame(job_title.employment_type.str.split(',').tolist(), index=job_title.title_id, columns = ['employment_type','employment_duration'])\n",
    "employment_type_unique = pd.DataFrame(data=employment_data_unique['employment_type'].unique(), columns=[\"employment_type\"])\n",
    "employment_type_unique.reset_index(level=0, inplace=True)\n",
    "employment_type_unique.rename(columns={'index': 'employment_type_id'}, inplace=True)\n",
    "employment_type_dict = dict(zip(employment_type_unique['employment_type'], employment_type_unique['employment_type_id']))\n",
    "\n",
    "employment_duration_unique = pd.DataFrame(data=employment_data_unique['employment_duration'].unique(), columns=[\"employment_duration\"])\n",
    "employment_duration_unique.reset_index(level=0, inplace=True)\n",
    "employment_duration_unique.rename(columns={'index': 'employment_duration_id'}, inplace=True)\n",
    "employment_duration_unique = dict(zip(employment_duration_unique['employment_duration'], employment_duration_unique['employment_duration_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create a DF of unique categories from job_posting['skills']\n",
    "posting_skills = pd.DataFrame(job_title.skills.str.split(',').tolist(), index=job_title.title_id).stack()\n",
    "posting_skills = posting_skills.str.lower()\n",
    "posting_skills = posting_skills.str.strip()\n",
    "posting_skills = posting_skills.reset_index([0, 'title_id'])\n",
    "posting_skills.columns = ['title_id', 'skills']\n",
    "# posting_skills.to_csv(r'/Users/aceinna_rishit/Documents/AWS/posting_skills_temp.csv', index = False)\n",
    "skill_table = pd.DataFrame()\n",
    "skill_table = posting_skills.groupby(\"skills\").agg({\"title_id\": \"nunique\"}).rename(columns={'title_id': 'count_jobs'}).reset_index([0, 'skills'])\n",
    "skill_table.insert(0,'skill_id', range(0,len(skill_table['skills'])))\n",
    "skill_dict = dict(zip(skill_table['skills'], skill_table['skill_id']))\n",
    "\n",
    "# Replece skills with skill_id in posting_skills['skills']\n",
    "posting_skills['skills'] = posting_skills['skills'].replace(skill_dict)\n",
    "# Update posting_skills['skills'] to posting_skills['skills_id']\n",
    "posting_skills.rename(columns={'skills': 'skills_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat Functional Area field same as skills, create a unique table for funcitonal area and map functional area with the job_posting\n",
    "#  Create a DF of unique categories from job_posting['functional_area']\n",
    "posting_functional_areas = pd.DataFrame(job_title.functional_area.str.split(', |/').tolist(), index=job_title.title_id).stack()\n",
    "posting_functional_areas = posting_functional_areas.str.lower()\n",
    "posting_functional_areas = posting_functional_areas.str.strip()\n",
    "posting_functional_areas = posting_functional_areas.reset_index([0, 'title_id'])\n",
    "posting_functional_areas.columns = ['title_id', 'functional_area']\n",
    "# posting_functional_areas.to_csv(r'/Users/aceinna_rishit/Documents/AWS/posting_functional_areas_temp.csv', index = False)\n",
    "\n",
    "functional_area_table = pd.DataFrame()\n",
    "functional_area_table = posting_functional_areas.groupby(\"functional_area\").agg({\"title_id\": \"nunique\"}).rename(columns={'title_id': 'count_jobs'}).reset_index([0, 'functional_area'])\n",
    "functional_area_table.insert(0,'functional_area_id', range(0,len(functional_area_table['functional_area'])))\n",
    "functional_area_dict = dict(zip(functional_area_table['functional_area'], functional_area_table['functional_area_id']))\n",
    "\n",
    "# Replece functional_area with functional_area_id in posting_functional_area['functional_area']\n",
    "posting_functional_areas['functional_area'] = posting_functional_areas['functional_area'].replace(functional_area_dict)\n",
    "# Update posting_functional_area['functional_area'] to posting_functional_area['functional_area_id']\n",
    "posting_functional_areas.rename(columns={'functional_area': 'functional_area_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "job_id              21\n",
      "job_title           21\n",
      "company_id          21\n",
      "company_name        21\n",
      "category_id         21\n",
      "category            21\n",
      "role_category_id    20\n",
      "role_category       20\n",
      "job_role_id         21\n",
      "job_role            21\n",
      "employment_type     21\n",
      "location            21\n",
      "skills              21\n",
      "job_url             21\n",
      "salary_min          20\n",
      "salary_max          20\n",
      "experience_min      20\n",
      "experience_max      20\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Columns must be same length as key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-300-a19a775e7592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mjob_posting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mjob_posting\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'location_comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob_posting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mjob_posting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation_comments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mjob_posting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3035\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3036\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3037\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3062\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3063\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Columns must be same length as key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3064\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns must be same length as key"
     ]
    }
   ],
   "source": [
    "job_posting.insert(2, \"company_id\", job_posting[\"company_name\"].map(company_dict))\n",
    "job_posting.insert(4, \"category_id\", job_posting[\"category\"].map(category_dict))\n",
    "job_posting.insert(6, \"role_category_id\", job_posting[\"role_category\"].map(role_category_dict))\n",
    "job_posting.insert(8, \"job_role_id\", job_posting[\"job_role\"].map(job_role_dict))\n",
    "job_posting.drop('functional_area', inplace=True, axis=1)\n",
    "\n",
    "# Process Salary Column\n",
    "job_posting['salary'] = job_posting['salary'].map(lambda x: x.rstrip('PA.'))\n",
    "job_posting['salary'] = job_posting['salary'].map(lambda x: x.replace(',',''))\n",
    "job_posting[['salary_min','salary_max']] = job_posting.salary.str.split('-',expand=True)\n",
    "job_posting.salary_min.replace('Not disclosed', np.nan, regex=True, inplace=True)\n",
    "job_posting.salary_max.fillna(value=np.nan,inplace=True)\n",
    "job_posting.drop('salary', inplace=True, axis=1)\n",
    "\n",
    "# Process Experience Range\n",
    "job_posting['experience'] = job_posting['experience'].str.rstrip(' Yrs')\n",
    "job_posting[['experience_min','experience_max']] = job_posting.experience.str.split('-',expand=True)\n",
    "job_posting.experience_min.fillna(value=np.nan,inplace=True)\n",
    "job_posting.experience_max.fillna(value=np.nan,inplace=True)\n",
    "job_posting.drop('experience', inplace=True, axis=1)\n",
    "\n",
    "#  Process Location\n",
    "# print(job_posting['location'].count)\n",
    "cont = job_posting['location'].count()\n",
    "print(cont)\n",
    "print(job_posting.count())\n",
    "\n",
    "job_posting.location.fillna(value=np.nan,inplace=True)\n",
    "job_posting[['location','location_comments']] = job_posting.location.str.split(',',expand=True)\n",
    "job_posting.location_comments.fillna(value=np.nan,inplace=True)\n",
    "job_posting.drop('location', inplace=True, axis=1)\n",
    "\n",
    "print(job_posting['location'].head())\n",
    "print(job_posting['location_comments'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/job_title.csv', index = False)\n",
    "company_unique.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/company_unique.csv', index = False)\n",
    "category_unique.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/category_unique.csv', index = False)\n",
    "role_category_unique.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/role_category_unique.csv', index = False)\n",
    "job_role_unique.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/job_role_unique.csv', index = False)\n",
    "skill_table.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/skills_table.csv', index = False)\n",
    "posting_skills.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/posting_skills.csv', index = False)\n",
    "functional_area_table.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/functional_area_table.csv', index = False)\n",
    "posting_functional_areas.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/posting_functional_areas.csv', index = False)\n",
    "job_posting.to_csv(r'/Users/aceinna_rishit/Documents/AWS/tables/job_posting.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
